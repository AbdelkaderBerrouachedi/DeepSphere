{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph ConvNet for cosmology: demo of spherical convolution\n",
    "\n",
    "[Nathanaël Perraudin](http://perraudin.info), [Michaël Defferrard](http://deff.ch), Tomasz Kacprzak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this small notebook, we test an implementation of a spherical convolution. The general idea is to use a graph instead of the tradtionial 2 dimensional grid as a support for convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import healpy as hp\n",
    "from pygsp import filters\n",
    "\n",
    "from scnn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (17, 5)  # (9, 4) for matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by constructing two small graphs on the healpix sampling scheme and visualizing them (with and without edges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "G = utils.healpix_graph(nside=8, nest=True)\n",
    "G.plotting.update(vertex_size=10)\n",
    "G.plot(show_edges=False, ax=ax)\n",
    "\n",
    "ax = fig.add_subplot(122, projection='3d')\n",
    "G = utils.healpix_graph(nside=4, nest=True)\n",
    "G.plotting.update(vertex_size=20)\n",
    "G.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The healpix sampling induces an 8 nearest neighbors graph, i.e. a graph where each vertex is connected to 8 vertices. Some vertices are however connected to 7 neighbors only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.unique(G.d):\n",
    "    print('Number of nodes with {} neighbors: {}'.format(i, np.sum(G.d == i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Fourier basis\n",
    "\n",
    "Graph convolution is defined as the pointwise multiplication in the graph spectral domain. Hence it is important to verify the spectral property of the graph. Note that this operation requires the diagonalization of the Laplacian, which is very costly in computations and mermory. Nevertheless, when it comes to convolution, their exist fast methods that only require sparse matrix multiplications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = utils.healpix_graph(nside=16, lap_type='normalized', nest=True, dtype=np.float64)\n",
    "\n",
    "print('max weighted degree: {:.2f}'.format(G.dw.max()))\n",
    "print('min weighted degree: {:.2f}'.format(G.dw.min()))\n",
    "print('mean weighted degree: {:.2f}'.format(G.dw.mean()))\n",
    "print('Is the graph directed? {}'.format(G.is_directed()))\n",
    "print('Number of nodes: {}'.format(G.N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvectors are obtained by diagonalizing the graph laplacian defined as $L=I-D^{\\frac{1}{2}}WD^{\\frac{1}{2}}$, where $W$ is the weight/adjacency matrix and $D$ the degree matrix. \n",
    "\n",
    "The Fourier basis $U$ by definition satisfies\n",
    "$$ L  = U \\Lambda U^*. $$\n",
    "Here the eigenvalues contained in the diagonal of $\\Lambda$ somehow correspond to the graph squared frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all eigenvectors.\n",
    "G.compute_fourier_basis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean: {}'.format(np.mean(np.abs(G.U.ravel()))))\n",
    "print('Min: {}'.format(np.min(G.U.ravel())))\n",
    "print('Max: {}'.format(np.max(G.U.ravel())))\n",
    "print('Perline: {}'.format(np.max(G.U, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us display a few Fourier modes on the healpix map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ne = 16\n",
    "\n",
    "for ind in range(ne):\n",
    "    hp.mollview(G.U[:, ind], \n",
    "                title='Eigenvector {}'.format(ind), \n",
    "                nest=True, \n",
    "                sub=(np.sqrt(ne), np.sqrt(ne), ind+1),\n",
    "                max=np.max(np.abs(G.U[:, :ne])),\n",
    "                min=-np.max(np.abs(G.U[:, :ne])),\n",
    "                cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also check higher frequency modes as they can be more localized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND = 3000\n",
    "fig = plt.figure(figsize=(3, 2))\n",
    "hp.mollview(G.U[:, IND], title=\"Eigenvector {}\".format(IND), nest=True, cbar=False, sub=(1, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most localized eigenvector is considered to be the one with the heighest coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.argmax(np.max(np.abs(G.U), axis=0))\n",
    "fig = plt.figure(figsize=(3, 2))\n",
    "hp.mollview(G.U[:, ind], title=\"Eigenvector {}\".format(ind), nest=True, cbar=False, sub=(1, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This eigenvector is clearly very localized. Let us display the modulus of the Fourier eigenvector to have a more general idea about all eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.imshow(np.abs(G.U), cmap='Greys');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Convolution on graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolution of a signal $f$ and a kernel $k(x)$ on a graph is defined as the pointwise multiplication in the spectral domain, i.e.\n",
    "$$f_c  = U k(\\Lambda)U^*f. $$\n",
    "Here $U^*f$ is the graph Fourier transform of $f$ and $k(\\Lambda)$ is a diagonal matrix where the kernel $k$ is applied on each element of the diagonal of $\\Lambda$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start with the heat diffusion problem. We solve the following equation on the graph:\n",
    "$$ L f(t) = \\tau \\partial_t f(t),$$\n",
    "where $f(t): \\mathbb{R}_+ \\rightarrow \\mathbb{R}^N$ is a multivariate function depending on the time, $L$ a positive semi-definite matrix representing the Laplacian of a graph, and $\\tau$ a constant.\n",
    "\n",
    "Given the vector $f_0 = f(0)$, the solution of this equation for time $t$ can be written as:\n",
    "$$ f(t) = K_t(L) f_0, $$\n",
    "where \n",
    "$$ K_t(L) = e^{-\\tau t L}.$$\n",
    "In the equation $f(t) = K_t(L) f_0$, the kernel $K_t(x)=e^{-\\tau t x}$ can be considered as the convolution kernel and the heat diffusion problem can be solved using a simple convolution on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taus = [5, 10, 20, 50]\n",
    "hf = filters.Heat(G, tau=taus)\n",
    "fig, ax = plt.subplots()\n",
    "hf.plot(plot_eigenvalues=True, show_sum=False, ax=ax)\n",
    "ax.set_title('Filter frequency response');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind0 in [0, 500]:\n",
    "    \n",
    "    sig = np.zeros(G.N)\n",
    "    sig[ind0] = 1\n",
    "    conv = hf.analyze(sig)\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    for i, tau in enumerate(taus):\n",
    "        hp.mollview(conv[:, i], \n",
    "                    title='ind0={}, tau={}'.format(ind0, tau), \n",
    "                    nest=True, \n",
    "                    sub=(np.sqrt(len(taus)), np.sqrt(len(taus)), i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Smoothing a Planck map\n",
    "\n",
    "Let us play with with a Planck map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_cmb, map_noise, map_mask = hp.read_map('data/COM_CMB_IQU-smica_1024_R2.02_full.fits', field=(0, 1, 3), nest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(map_cmb, title='cmb', nest=True)\n",
    "# hp.mollview(map_noise, title='noise', cmap='RdBu')\n",
    "# hp.mollview(map_mask, title='mask', cmap='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us first select a lower resolution: NSIDE=256, making the total number of pixels: $ N = 256^2 \\cdot 12=786432.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nside = 256\n",
    "map_cmb_lores = hp.ud_grade(map_cmb, nside_out=nside, order_in='NESTED')\n",
    "G = utils.healpix_graph(nside=nside, nest=True)\n",
    "G.estimate_lmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let apply our heat operator. It will smooth the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taus = [5, 10, 20, 50]\n",
    "hf = filters.Heat(G, tau=taus)\n",
    "conv_map_lowres = hf.analyze(map_cmb_lores)\n",
    "\n",
    "fig = plt.figure(figsize=(9, 6))\n",
    "for i, tau in enumerate(taus):\n",
    "    hp.mollview(conv_map_lowres[:, i], \n",
    "                title=\"Tau: {}\".format(tau), \n",
    "                nest=True, \n",
    "                sub=(np.sqrt(len(taus)), np.sqrt(len(taus)), i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Power spectral density\n",
    "\n",
    "Let us now compute the power spectral density on the sphere. This is going to be different than the traditionial one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_graph_psd(G, sig, Nrand=10, Npoint=30):\n",
    "    \"\"\"Estimate the power spectral density on graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    G : graph\n",
    "    sig : ndarray\n",
    "        Signal whose PSD is to be estimated.\n",
    "    Nrand : int\n",
    "        Number of random signals used for the estimation.\n",
    "    Npoint : int\n",
    "        Number of points at which the PSD is estimated.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define filterbank.\n",
    "    g = filters.Itersine(G, Nf=Npoint, overlap=2)\n",
    "    mu = np.linspace(0, G.lmax, Npoint)\n",
    "    \n",
    "    # Filter signal.\n",
    "    sig_filt = g.filter(sig, method='chebyshev', order=2*Npoint)\n",
    "    sig_dist = np.sum(sig_filt**2, axis=0)\n",
    "    if sig_dist.ndim > 1:\n",
    "        sig_dist = np.mean(sig_dist, axis=0).squeeze()\n",
    "    \n",
    "    # Estimate the eigenvectors by filtering random signals.\n",
    "    rand_sig = np.random.binomial(n=1, p=0.5, size=[G.N, Nrand]) * 2 - 1\n",
    "    rand_sig_filered = g.filter(rand_sig, method='chebyshev', order=2*Npoint)\n",
    "    eig_dist = np.mean(np.sum(rand_sig_filered**2, axis=0), axis=0).squeeze()\n",
    "    \n",
    "    # Compute PSD.\n",
    "    psd_values = sig_dist / eig_dist\n",
    "    inter = interp1d(mu, psd_values, kind='linear')\n",
    "    \n",
    "    return filters.Filter(G, inter), (mu, psd_values)\n",
    "\n",
    "psd_filter, psd_point = estimate_graph_psd(G, map_cmb_lores, Nrand=5, Npoint=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_filter.plot()\n",
    "plt.plot(*psd_point, 'x')\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(*psd_point);"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
