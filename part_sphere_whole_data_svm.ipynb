{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SVM + Histogram to classify the map\n",
    "\n",
    "[Nathanaël Perraudin](http://perraudin.info), [Michaël Defferrard](http://deff.ch), Tomasz Kacprzak\n",
    "\n",
    "In this notebook, we use the full augmented dataset to fit a linear SVM to the histogram of the maps to build a classifier.\n",
    "\n",
    "A few remarks:\n",
    "* Kernelized SVM is worse than linear SVM\n",
    "* This script might require a lot of ram (32Gigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import healpy as hp\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from scnn import models\n",
    "from scnn import utils\n",
    "from scnn.data import LabeledDatasetWithNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (17, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nside = 1024\n",
    "order = 2  # 1,2,4,8 correspond to 12,48,192,768 parts of the sphere.\n",
    "sigma_noise = 5\n",
    "EXP_NAME = '40sim_{}sides_1arcmin_{}noise_{}order'.format(Nside, sigma_noise, order)\n",
    "data_path = 'data/same_psd/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = np.load(data_path+'smoothed_class1.npz')['arr_0']\n",
    "ds2 = np.load(data_path+'smoothed_class2.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Samples creation\n",
    "\n",
    "We here create samples by dividing the two complete spheres in patches (based on healpix sampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasample = dict()\n",
    "datasample['class1'] = np.vstack([utils.hp_split(el, order=order) for el in ds1])\n",
    "datasample['class2'] = np.vstack([utils.hp_split(el, order=order) for el in ds2])\n",
    "del ds1\n",
    "del ds2\n",
    "\n",
    "print('The data is of shape {}'.format(datasample['class1'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Normalization and train / test split \n",
    "\n",
    "Let us split the data into training and testing sets. The raw data is stored into `x_raw` and the histograms into `x_trans`. As a transformation, we cannot use the power spectrum density. Hence we do an histogram of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and transform the data, i.e. extract features.\n",
    "x_raw = np.vstack((datasample['class1'], datasample['class2']))\n",
    "x_raw_std = np.std(x_raw)\n",
    "x_raw = x_raw / x_raw_std # Apply some normalization\n",
    "rs = np.random.RandomState(0)\n",
    "x_noise = x_raw + sigma_noise*rs.randn(*x_raw.shape)\n",
    "cmin = np.min(x_raw)\n",
    "cmax = np.max(x_raw)\n",
    "\n",
    "# Create the label vector.\n",
    "labels = np.zeros([x_raw.shape[0]], dtype=int)\n",
    "labels[len(datasample['class1']):] = 1\n",
    "\n",
    "\n",
    "ret = train_test_split(x_raw, x_noise, labels, train_size=0.8, shuffle=True, random_state=0)\n",
    "x_raw_train, x_raw_validation, x_noise_train, x_noise_validation, labels_train, labels_validation = ret\n",
    "\n",
    "print('Class 1 VS class 2')\n",
    "print('  Training set: {} / {}'.format(np.sum(labels_train==0), np.sum(labels_train==1)))\n",
    "print('  Validation set: {} / {}'.format(np.sum(labels_validation==0), np.sum(labels_validation==1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = LabeledDatasetWithNoise(x_raw_train, \n",
    "                                   labels_train, \n",
    "                                   start_level=sigma_noise, \n",
    "                                   end_level=sigma_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nloop = 10\n",
    "ntrain = len(x_raw_train)\n",
    "N = ntrain * nloop\n",
    "nbatch = ntrain // 4\n",
    "it = training.iter(nbatch)\n",
    "\n",
    "x_trans_train = []\n",
    "labels_train = []\n",
    "for i in range(nloop*4):\n",
    "    x,l = next(it)\n",
    "    x_trans_train.append(utils.histogram(x, cmin, cmax))\n",
    "    labels_train.append(l)\n",
    "x_trans_train = np.concatenate(x_trans_train, axis=0)\n",
    "labels_train = np.concatenate(labels_train, axis=0)\n",
    "# Scale the data\n",
    "x_trans_train_mean = np.mean(x_trans_train)\n",
    "x_trans_train = x_trans_train - x_trans_train_mean\n",
    "x_trans_train_std = np.std(x_trans_train)\n",
    "x_trans_train = x_trans_train / x_trans_train_std\n",
    "\n",
    "x_trans_validation = (utils.histogram(x_noise_validation, cmin, cmax) - x_trans_train_mean) / x_trans_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_svc_rbf(x_train, label_train, x_test, label_test):\n",
    "    clf = SVC(kernel='rbf')\n",
    "    clf.fit(x_train, label_train)\n",
    "    pred = clf.predict(x_train)\n",
    "    error_train = sum(np.abs(pred - label_train)) / len(label_train)\n",
    "    pred = clf.predict(x_test)\n",
    "    error_test = sum(np.abs(pred - label_test)) / len(label_test)\n",
    "    return error_train, error_test\n",
    "def err_svc_linear(x_train, label_train, x_test, label_test):\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(x_train, label_train)\n",
    "    pred = clf.predict(x_train)\n",
    "    error_train = sum(np.abs(pred - label_train)) / len(label_train)\n",
    "    pred = clf.predict(x_test)\n",
    "    error_test = sum(np.abs(pred - label_test)) / len(label_test)\n",
    "    return error_train, error_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = list(ntrain//12 * np.linspace(1,6,num=6).astype(np.int))\n",
    "nsamples +=list(ntrain//2 * np.linspace(1,12,num=12).astype(np.int))\n",
    "err_train = np.zeros(shape=[len(nsamples)])\n",
    "err_validation = np.zeros(shape=[len(nsamples)])\n",
    "err_train[:] = np.nan\n",
    "err_validation[:] = np.nan\n",
    "\n",
    "for i, n in enumerate(nsamples):\n",
    "    print('{} Solve it for {} samples'.format(i,n))\n",
    "    %time err_train[i], err_validation[i] = err_svc_linear(x_trans_train[:n], labels_train[:n] ,x_trans_validation, labels_validation)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nsamples,err_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nsamples,err_validation*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variations we observe are due to slight overfitting of the validataion set. Clearly we have enough samples to reach the saturation of our classifier. Hence, for the testing set, we simply use all the data. \n",
    "\n",
    "Computatition might take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testing_dataset(order, sigma_noise, x_raw_std):\n",
    "    ds1 = np.load('data/same_psd_testing/smoothed_class1.npz')['arr_0']\n",
    "    ds2 = np.load('data/same_psd_testing/smoothed_class2.npz')['arr_0']\n",
    "    \n",
    "    datasample = dict()\n",
    "    datasample['class1'] = np.vstack([utils.hp_split(el, order=order) for el in ds1])\n",
    "    datasample['class2'] = np.vstack([utils.hp_split(el, order=order) for el in ds2])\n",
    "    \n",
    "    x_raw = np.vstack((datasample['class1'], datasample['class2']))\n",
    "    x_raw = x_raw / x_raw_std # Apply some normalization\n",
    "    \n",
    "    rs = np.random.RandomState(1)\n",
    "    x_noise = x_raw + sigma_noise*rs.randn(*x_raw.shape)\n",
    "    \n",
    "    # Create the label vector.\n",
    "    labels = np.zeros([x_raw.shape[0]], dtype=int)\n",
    "    labels[len(datasample['class1']):] = 1\n",
    "    \n",
    "    return x_noise, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_noise_test, labels_test = get_testing_dataset(order, sigma_noise, x_raw_std)\n",
    "x_trans_test = (utils.histogram(x_noise_test, cmin, cmax) - x_trans_train_mean) / x_trans_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_train, e_validation = err_svc_linear(x_trans_train, labels_train ,x_trans_validation, labels_validation)\n",
    "print('The validation error is {}%'.format(e_validation*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_train, e_test = err_svc_linear(x_trans_train, labels_train ,x_trans_test, labels_test)\n",
    "print('The test error is {}%'.format(e_test*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(EXP_NAME,[nsamples, err_train, err_validation, e_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
