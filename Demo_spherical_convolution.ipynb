{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of spherical convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this small notebook, we test an implementation of a spherical convolution. The general idea is to use a graph instead of the tradtionial 2 dimensional grid as a support for convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import healpy as hp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pygsp\n",
    "pygsp.plotting.BACKEND = 'matplotlib'\n",
    "from pprint import pprint\n",
    "import math\n",
    "import scipy\n",
    "import itertools\n",
    "\n",
    "from scnn import utils, models\n",
    "\n",
    "%matplotlib notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by defining the graph on the healpix sampling scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "NSIDE = 8\n",
    "NPIX = NSIDE**2*12\n",
    "[x,y,z] = hp.pix2vec(NSIDE, range(NPIX),nest=True)\n",
    "ax.scatter(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a 8 nearest neighboor graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # build a healpix graph from NSIDE\n",
    "# def healpix_graph(nside=16, nest=False, lap_type='normalized'):\n",
    "#     NPIX = nside**2*12 # number of pixels\n",
    "#     pix = range(NPIX)\n",
    "    \n",
    "#     # 1) get the coordinates\n",
    "#     [x,y,z] = hp.pix2vec(nside, pix,nest=nest)\n",
    "#     coords = np.vstack([x,y,z]).transpose()\n",
    "    \n",
    "#     # 2) get the 8 neighboors\n",
    "#     [theta, phi] = hp.pix2ang(nside, pix, nest = nest)\n",
    "#     index_neighboor = hp.pixelfunc.get_all_neighbours(nside,theta=theta, phi=phi, nest = nest)\n",
    "    \n",
    "#     # 3) build the adjacency matrix\n",
    "# #     row_index = []\n",
    "# #     col_index = []\n",
    "# #     for row in pix:\n",
    "# #         for col in index_neighboor[:,row]:\n",
    "# #             if col>=0:\n",
    "# #                 row_index.append(row)\n",
    "# #                 col_index.append(col)\n",
    "#     col_index = np.reshape(index_neighboor.T,[NPIX*8])\n",
    "#     row_index = np.reshape(np.reshape(np.array(list(pix)*8),[8,NPIX]).T,[8*NPIX])\n",
    "#     good_index = col_index >= 0\n",
    "#     col_index = col_index[good_index]\n",
    "#     row_index = row_index[good_index]\n",
    "    \n",
    "#     # index_sparse = [(row,col) for row in range(len(ind)) for col in index_neighboor[:,row]]\n",
    "#     dist = np.array([sum((coords[row]-coords[col])**2) for row,col in zip(row_index,col_index)])\n",
    "#     mean_dist = np.mean(dist)\n",
    "#     w = np.exp(-dist/(2*mean_dist))\n",
    "#     W = scipy.sparse.csr_matrix((w,(row_index, col_index)), shape=(NPIX,NPIX))\n",
    "    \n",
    "#     G = pygsp.graphs.Graph(W, gtype='healpix', lap_type=lap_type, coords=coords)\n",
    "#     return G\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a small graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = utils.healpix_graph(nside=16,lap_type='normalized', nest = True, dtype=np.float64)\n",
    "print('max degree: {}'.format(np.max(np.sum(G.W,axis=0))))\n",
    "print('min degree: {}'.format(np.min(np.sum(G.W,axis=0))))\n",
    "print('mean degree: {}'.format(np.mean(np.sum(G.W,axis=0))))\n",
    "print('Is the graph directed? {}'.format(G.is_directed()))\n",
    "print('Number of nodes: {}'.format(G.N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph convolution is defined as the pointwise multiplication in the graph spectral domain. Hence it is important to veryfy the spectral property of the graph. Note that this operation requires the diagonalization of the Laplacian, which is very costly in computations and mermory. Nevertheless, when it comes to convolution, their exist fast methods that only require sparse matrix multiplications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvectors are obtained by diagonalizing the graph laplacian defined as $L=I-D^{\\frac{1}{2}}WD^{\\frac{1}{2}}$, where $W$ is the weight/adjacency matrix and $D$ the degree matrix. \n",
    "\n",
    "The Fourier basis $U$ by definition satisfies\n",
    "$$ L  = U \\Lambda U^*. $$\n",
    "Here the eigenvalues contained in the diagonal of $\\Lambda$ somehow correspond to the graph squared frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all eigenvectors\n",
    "G.compute_fourier_basis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Uv = np.reshape(G.U,[G.N**2,1])\n",
    "print('Mean: {}'.format(np.mean(np.abs(Uv))))\n",
    "print('Min: {}'.format(np.min(Uv)))\n",
    "print('Max: {}'.format(np.max(Uv)))\n",
    "print('Perline: {}'.format(np.max(G.U,axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us display a few Fourier modes on the healpix map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 4))\n",
    "ne = 16\n",
    "\n",
    "for ind in range(ne):\n",
    "    hp.mollview(G.U[:,ind], \n",
    "                title=\"Eigenvector {}\".format(ind), \n",
    "                nest=True, \n",
    "                sub=(math.sqrt(ne),math.sqrt(ne),ind+1),\n",
    "                max=np.max(np.abs(G.U[:,:ne])),\n",
    "                min=-np.max(np.abs(G.U[:,:ne])),\n",
    "                cbar=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also check higher frequency modes as they can be more localized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 3000\n",
    "fig = plt.figure(figsize=(3, 2))\n",
    "hp.mollview(G.U[:,ind], title=\"Eigenvector {}\".format(ind), nest=True, cbar=False, sub=(1,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most localized eigenvector is considered to be the one with the heighest coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.argmax(np.max(np.abs(G.U),axis=0))\n",
    "fig = plt.figure(figsize=(3, 2))\n",
    "hp.mollview(G.U[:,ind], title=\"Eigenvector {}\".format(ind), nest=True, cbar=False, sub=(1,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This eigenvector is clearly very localized. Let us display the modulus of the Fourier eigenvector to have a more general idea about all eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.imshow(np.abs(G.U), cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of the convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolution of a signal $f$ and a kernel $k(x)$ on a graph is defined as the pointwise multiplication in the spectral domain, i.e.\n",
    "$$f_c  = U k(\\Lambda)U^*f. $$\n",
    "Here $U^*f$ is the graph Fourier transform of $f$ and $k(\\Lambda)$ is a diagonal matrix where the kernel $k$ applied on each element of the diagonal of $\\Lambda$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start with the heat diffusion problem. We solve the following equation on the graph:\n",
    "$$ L f(t) = \\tau \\partial_t f(t),$$\n",
    "where $f(t): \\mathbb{R}_+ \\rightarrow \\mathbb{R}^N$ is a multivariate function depending on the time, $L$ a positive semi-definite matrix representing the Laplacian on a graph, and $\\tau$ a constant.\n",
    "\n",
    "Given the vector $f_0 = f(0)$, the solution of this equation for time $t$ can be written as:\n",
    "$$ f(t) = K_t(L) f_0, $$\n",
    "where \n",
    "$$ K_t(L) = e^{-\\tau t L}.$$\n",
    "In the equation $f(t) = K_t(L) f_0$, the kernel $K_t(x)=e^{-\\tau t x}$ can be consdired as the convolution kernel and the heat diffusion problem can be solved using a simple convolution on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = [5,10,20,50]\n",
    "hf = pygsp.filters.Heat(G, tau=tau)\n",
    "fig, ax = plt.subplots()\n",
    "hf.plot(plot_eigenvalues=True, show_sum=False, ax=ax)\n",
    "_ = ax.set_title('Filter frequency response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind0 = 0\n",
    "sig = np.zeros([G.N])\n",
    "sig[ind0]=1\n",
    "conv = hf.analyze(sig)\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "ne = 4\n",
    "\n",
    "for ind in range(ne):\n",
    "    hp.mollview(conv[:,ind], \n",
    "                title=\"Tau: {}\".format(tau[ind]), \n",
    "                nest=True, \n",
    "                sub=(2,2,ind+1))\n",
    "\n",
    "ind0 = 500\n",
    "sig = np.zeros([G.N])\n",
    "sig[ind0]=1\n",
    "conv = hf.analyze(sig)\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "ne = 4\n",
    "\n",
    "for ind in range(ne):\n",
    "    hp.mollview(conv[:,ind], \n",
    "                title=\"Tau: {}\".format(tau[ind]), \n",
    "                nest=True, \n",
    "                sub=(2,2,ind+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing using Planck map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with with a Planck map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_cmb, map_noise, map_mask = hp.read_map('data/COM_CMB_IQU-smica_1024_R2.02_full.fits', field = (0,1,3), nest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(map_cmb, title='cmb', nest=True)\n",
    "# hp.mollview(map_noise, title='noise', cmap='RdBu')\n",
    "# hp.mollview(map_mask, title='mask', cmap='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us first select a lower resolution: NSIDE=256, making the total number of pixels: $ N = 256^2*12=786432.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nside = 256\n",
    "map_cmb_lores = hp.ud_grade(map_cmb, nside_out=nside, order_in='NESTED')\n",
    "G = utils.healpix_graph(nside=nside, nest = True)\n",
    "G.estimate_lmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let apply our heat operator. It will smooth the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = [5,10,20,50]\n",
    "hf = pygsp.filters.Heat(G, tau=tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_map_lowres = hf.analyze(map_cmb_lores)\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ne = 4\n",
    "\n",
    "for ind in range(ne):\n",
    "    hp.mollview(conv_map_lowres[:,ind], \n",
    "                title=\"Tau: {}\".format(tau[ind]), \n",
    "                nest=True, \n",
    "                sub=(2,2,ind+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now compute the power spectral density on the sphere. This is going to be different than the traditionial one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_graph_psd(G, sig, Nrand=10, Npoint=30):\n",
    "    from scipy.interpolate import interp1d\n",
    "    g = pygsp.filters.Itersine(G, Nf=Npoint, overlap=2)\n",
    "    mu = np.linspace(0,G.lmax,Npoint)\n",
    "\n",
    "    sig_filt = g.filter(sig, method='chebyshev', order=2*Npoint)\n",
    "#     sig_dist = np.mean(np.sum(sig_filt*sig_filt,axis=0),axis=0).squeeze()\n",
    "    sig_dist = np.sum(sig_filt*sig_filt,axis=0)\n",
    "    if len(sig_dist.shape)>1:\n",
    "        sig_dist = np.mean(sig_dist,axis=0).squeeze()\n",
    "    \n",
    "    rand_sig = np.random.binomial(n=1,p=0.5, size=[G.N,Nrand])*2 - 1\n",
    "    rand_sig_filered = g.filter(rand_sig, method='chebyshev', order=2*Npoint )\n",
    "    eig_dist = np.mean(np.sum(rand_sig_filered*rand_sig_filered,axis=0),axis=0).squeeze()\n",
    "    \n",
    "    psd_values = sig_dist/eig_dist\n",
    "    inter = interp1d(mu, psd_values, kind='linear')\n",
    "    return pygsp.filters.Filter(G, inter), (mu,psd_values)\n",
    "\n",
    "psd_filter, psd_point = estimate_graph_psd(G, map_cmb_lores, Nrand=5, Npoint=30)\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_filter.plot()\n",
    "plt.plot(*psd_point, 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(*psd_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
